{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##How can LLM prompting be abstracted?\n",
        "\n",
        "LangChain's PromptTemplate enables multiple arguments to be packaged as a single input to the LLM.\n",
        "\n",
        "This project uses [OpenAI's GPT 3.5 Turbo Instruct](https://platform.openai.com/docs/models/gpt-3-5-turbo)."
      ],
      "metadata": {
        "id": "7BMOMcdYbdo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "4KLgF3lVb103"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kup4TYlg7Rnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75ad2ad-6483-4b6e-e41f-ad6c99ee8aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-core 0.3.50 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.21 which is incompatible.\n",
            "albumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 1.10.21 which is incompatible.\n",
            "google-genai 1.9.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.21 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m/bin/bash: line 1: 3.0.0,: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# download & install libraries\n",
        "!pip --quiet install openai==0.27.8 # LLM\n",
        "!pip --quiet install langchain==0.0.208 # framework for working with LLMs\n",
        "!pip --quiet install pydantic<3.0.0,>=2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run this project you'll need an OpenAI account, which you will use to obtain an OpenAI API key.  Keep your API key secret.\n",
        "\n",
        "While creating these lessons, I loaded my account with a \\$5.00 credit and turned OFF Auto Recharge.  This means that when the balance reaches \\$0, requests using this API key will stop working.  While creating these lessons, I ended up using only $0.43 in total.\n",
        "\n",
        "*   [Directions for obtaining an OpenAI API Key](https://help.openai.com/en/)\n",
        "*   [Create/manage your OpenAI API keys](https://platform.openai.com/api-keys)\n",
        "*   [Track your OpenAI API key usage/costs](https://platform.openai.com/usage)\n",
        "\n",
        "Example (not a real key):\n",
        "> %env OPENAI_API_KEY=uy-test-sdf87ewrkhjcdsoiewe2DSFIIF234234jhk23rHJJKH323jk"
      ],
      "metadata": {
        "id": "n9J9ejBMcFy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPdlxTen6gu5"
      },
      "outputs": [],
      "source": [
        "# paste your OpenAI API key without quotation marks\n",
        "#%env OPENAI_API_KEY=\n",
        "#%env OPENAI_API_KEY="
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constructing a PromptTemplate"
      ],
      "metadata": {
        "id": "duIugWd6b8d_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xSgkB0S7eKp"
      },
      "outputs": [],
      "source": [
        "# import LangChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fUQTj37-K-f"
      },
      "outputs": [],
      "source": [
        "# to use Google Colab Secrets\n",
        "from google.colab import userdata\n",
        "\n",
        "# load API key from Google Colab Secret\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# import OpenAI LLM\n",
        "import openai\n",
        "\n",
        "# instantiate OpenAI\n",
        "# will not run without first providing your OpenAI API key above\n",
        "# client = openai.OpenAI(api_key=api_key)\n",
        "# client = openai.OpenAI(api_key=api_key) # This line is causing the error\n",
        "# Replacing the above line with the one below.\n",
        "# openai.api_key = api_key # Setting the API key directly, This is not enough for langchain\n",
        "\n",
        "# initialize the large language model\n",
        "# will not run without providing an OPENAI_API_KEY above\n",
        "\n",
        "# temperature set to 0.9 for more creativity\n",
        "# Pass the api_key directly to the OpenAI class\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9, openai_api_key=api_key) # Instantiating the language model, providing api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLxDLAj8-Kab"
      },
      "outputs": [],
      "source": [
        "# initialize a PromptTemplate with 2 parameters:\n",
        "#     input_variables – list of value types to use while prompting\n",
        "#     template – text prompt that includes input_variables\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"activity\"],\n",
        "    template=\"Write a numbered list of educational field trips for a new high school club focused on {activity}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assemble a chain that includes both llm & prompt\n",
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "zQbeVVLZBViQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain user input\n",
        "user_activity = input(\"What's your favorite food? > \")\n",
        "\n",
        "# run the chain, providing argument(s) for the input_variables\n",
        "print(chain.run(user_activity))\n",
        "\n",
        "\n",
        "# TINKER:\n",
        "\n",
        "# 1) Run with different user inputs\n",
        "# 2) Change the template string in the PromptTemplate"
      ],
      "metadata": {
        "id": "H6YEViymBYAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67eea5f-cddb-4bad-c455-3e535c9438fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What's your favorite food? > NY steak\n",
            "\n",
            "\n",
            "1. Visit a local ranch or farm to learn about the process of raising cattle for meat production and the importance of ethical and sustainable farming practices.\n",
            "2. Tour a meat processing plant to see how NY steaks are processed and packaged for distribution to restaurants and grocery stores.\n",
            "3. Attend a cooking class taught by a professional chef, focusing on techniques for preparing and cooking NY steaks.\n",
            "4. Visit a butcher shop to learn about different cuts of beef and how they are selected and prepared for sale.\n",
            "5. Meet with a nutritionist to discuss the nutritional benefits of incorporating NY steaks into a balanced diet.\n",
            "6. Attend a food safety workshop to learn about proper handling and preparation techniques for meat products.\n",
            "7. Take a trip to a high-end steakhouse to experience the dining atmosphere and taste different variations of NY steaks.\n",
            "8. Visit a local butcher or meat market to see how they source and select their NY steaks and learn about the importance of buying from local, sustainable sources.\n",
            "9. Attend a demonstration by a certified meat grader to learn about the grading and labeling process for NY steaks and how it affects the quality and price of the meat.\n",
            "10. Meet with a representative from a cattle ranching association to learn about the history and culture of NY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A more complex PromptTemplate"
      ],
      "metadata": {
        "id": "axQ48I9eSGfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize a PromptTemplate with 3 parameters:\n",
        "#     input_variables – list of value types to use while prompting\n",
        "#     template – text prompt that includes input_variables\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"color\", \"animal\", \"food\"],\n",
        "    template=\"Write a poem about a {color} {animal} that enjoys eating {food}\"\n",
        ")\n",
        "\n",
        "# assemble a chain that includes both llm & PromptTemplate\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# obtain user input\n",
        "user_color = input(\"Favorite color > \")\n",
        "user_animal = input(\"Favorite animal > \")\n",
        "user_food = input(\"Favorite food > \")\n",
        "\n",
        "# create an object that holds all user inputs\n",
        "user_inputs = {\"color\": user_color, \"animal\": user_animal, \"food\": user_food}\n",
        "\n",
        "# run the chain, providing argument(s) for the input_variables\n",
        "print(chain.run(user_inputs))\n",
        "\n",
        "\n",
        "# TINKER:\n",
        "\n",
        "# 1) Change the user input questions, renaming variable names to match\n",
        "#     Attributes in the user_input object should also be renamed\n",
        "#     input_variables in the PromptTemplate should also be renamed\n",
        "\n",
        "# 2) Change the string in the PromptTemplate, modifying how the user's inputs\n",
        "#     are used to prompt the LLM\n",
        "\n",
        "# 3) Change the number of user inputs, asking at least 1 additional question"
      ],
      "metadata": {
        "id": "XiGnrU6EOhT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5dadc2-fb8d-4bc0-cc36-c4ab1b1b19db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Favorite color > green\n",
            "Favorite animal > cat\n",
            "Favorite food > steak\n",
            "\n",
            "\n",
            "In a small town, there lived a strange cat,\n",
            "With a coat of emerald green, she was quite a sight to look at,\n",
            "Her eyes were bright and shiny, like two sparkling gems,\n",
            "And her paws were soft and dainty, like delicate stems.\n",
            "\n",
            "But what made her stand out, from other felines so,\n",
            "Was her love for a certain food, that most cats do not know,\n",
            "She would turn her nose up at fish or mouse,\n",
            "For her taste buds craved for something else in the house.\n",
            "\n",
            "It wasn't catnip or cream, as you may have guessed,\n",
            "But something far more extravagant, that she liked to digest,\n",
            "It was steak, oh glorious steak, cooked to perfection,\n",
            "The green cat's love for it, was beyond mere affection.\n",
            "\n",
            "She would sit by the window, waiting for her treat,\n",
            "And when the steak was served, she would purr with delight so sweet,\n",
            "Her eyes would gleam, and her tail would sway,\n",
            "As she savored every bite, in her own special way.\n",
            "\n",
            "People would often stop and stare, at the green cat's feast,\n",
            "For it was a peculiar sight, to see a feline feast,\n",
            "But she didn't care, for she was in her own little bliss,\n",
            "With\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}