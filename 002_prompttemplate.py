# -*- coding: utf-8 -*-
"""002 PromptTemplate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E1xWU5jVkr1-4vGMpFUoJwpk8vGMtC7Q

##How can LLM prompting be abstracted?

LangChain's PromptTemplate enables multiple arguments to be packaged as a single input to the LLM.

This project uses [OpenAI's GPT 3.5 Turbo Instruct](https://platform.openai.com/docs/models/gpt-3-5-turbo).

#Setup
"""

# download & install libraries
!pip --quiet install openai==0.27.8 # LLM
!pip --quiet install langchain==0.0.208 # framework for working with LLMs
!pip --quite install numpy<3.0.0,>=2.0.0
!pip --quiet install pydantic<3.0.0,>=2.0.0

"""To run this project you'll need an OpenAI account, which you will use to obtain an OpenAI API key.  Keep your API key secret.

While creating these lessons, I loaded my account with a \$5.00 credit and turned OFF Auto Recharge.  This means that when the balance reaches \$0, requests using this API key will stop working.  While creating these lessons, I ended up using only $0.43 in total.

*   [Directions for obtaining an OpenAI API Key](https://help.openai.com/en/)
*   [Create/manage your OpenAI API keys](https://platform.openai.com/api-keys)
*   [Track your OpenAI API key usage/costs](https://platform.openai.com/usage)

Example (not a real key):
> %env OPENAI_API_KEY=uy-test-sdf87ewrkhjcdsoiewe2DSFIIF234234jhk23rHJJKH323jk
"""

# paste your OpenAI API key without quotation marks
#%env OPENAI_API_KEY=
#%env OPENAI_API_KEY=

"""# Constructing a PromptTemplate"""

# import LangChain
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# to use Google Colab Secrets
from google.colab import userdata

# load API key from Google Colab Secret
api_key = userdata.get('OPENAI_API_KEY')

# import OpenAI LLM
import openai

# instantiate OpenAI
# will not run without first providing your OpenAI API key above
# client = openai.OpenAI(api_key=api_key)
# client = openai.OpenAI(api_key=api_key) # This line is causing the error
# Replacing the above line with the one below.
# openai.api_key = api_key # Setting the API key directly, This is not enough for langchain

# initialize the large language model
# will not run without providing an OPENAI_API_KEY above

# temperature set to 0.9 for more creativity
# Pass the api_key directly to the OpenAI class
llm = OpenAI(model="gpt-3.5-turbo-instruct", temperature=0.9, openai_api_key=api_key) # Instantiating the language model, providing api_key

# initialize a PromptTemplate with 2 parameters:
#     input_variables – list of value types to use while prompting
#     template – text prompt that includes input_variables
prompt = PromptTemplate(
    input_variables=["activity"],
    template="Write a numbered list of educational field trips for your family focused on {activity}"
)

# assemble a chain that includes both llm & prompt
chain = LLMChain(llm=llm, prompt=prompt)

# obtain user input
user_activity = input("What's your favorite activity? > ")

# run the chain, providing argument(s) for the input_variables
print(chain.run(user_activity))


# TINKER:

# 1) Run with different user inputs
# 2) Change the template string in the PromptTemplate

"""A more complex PromptTemplate"""

# initialize a PromptTemplate with 3 parameters:
#     input_variables – list of value types to use while prompting
#     template – text prompt that includes input_variables
prompt = PromptTemplate(
    input_variables=["color", "animal", "food"],
    template="Write a poem about a {color} {animal} that enjoys eating {food}"
)

# assemble a chain that includes both llm & PromptTemplate
chain = LLMChain(llm=llm, prompt=prompt)

# obtain user input
user_color = input("Favorite color > ")
user_animal = input("Favorite animal > ")
user_food = input("Favorite food > ")

# create an object that holds all user inputs
user_inputs = {"color": user_color, "animal": user_animal, "food": user_food}

# run the chain, providing argument(s) for the input_variables
print(chain.run(user_inputs))


# TINKER:

# 1) Change the user input questions, renaming variable names to match
#     Attributes in the user_input object should also be renamed
#     input_variables in the PromptTemplate should also be renamed

# 2) Change the string in the PromptTemplate, modifying how the user's inputs
#     are used to prompt the LLM

# 3) Change the number of user inputs, asking at least 1 additional question