{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##How can you modify the way an LLM approaches a prompt?\n",
        "\n",
        "**HumanMessage** contains what we normally consider a user prompt – WHAT we want the LLM to consider, such as a specific question or direction.\n",
        "\n",
        "**SystemMessage** contains the context – HOW we want the LLM to consider it, such as fulfilling a role or taking a specific tone.\n",
        "\n",
        "This project uses [OpenAI's GPT 3.5 Turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo)."
      ],
      "metadata": {
        "id": "XKZbmCq1UO7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "3AjYoW7VV0Ha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kup4TYlg7Rnq",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47214bd4-af9c-45e1-e748-3a7104abe5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.27.8)\n",
            "Collecting openai\n",
            "  Downloading openai-1.72.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.51)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.27)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.5.14)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.72.0-py3-none-any.whl (643 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m643.9/643.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, httpx-sse, tiktoken, pydantic-settings, openai, langchain_community\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 0.27.8\n",
            "    Uninstalling openai-0.27.8:\n",
            "      Successfully uninstalled openai-0.27.8\n",
            "  Attempting uninstall: langchain_community\n",
            "    Found existing installation: langchain-community 0.0.20\n",
            "    Uninstalling langchain-community-0.0.20:\n",
            "      Successfully uninstalled langchain-community-0.0.20\n",
            "Successfully installed httpx-sse-0.4.0 langchain_community-0.3.21 openai-1.72.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# download & install libraries\n",
        "!pip --quiet install openai\n",
        "!pip install --upgrade langchain langchain_community openai tiktoken\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run this project you'll need an OpenAI account, which you will use to obtain an OpenAI API key.  Keep your API key secret.\n",
        "\n",
        "While creating these lessons, I loaded my account with a \\$5.00 credit and turned OFF Auto Recharge.  This means that when the balance reaches \\$0, requests using this API key will stop working.  While creating these lessons, I ended up using only $0.43 in total.\n",
        "\n",
        "*   [Directions for obtaining an OpenAI API Key](https://help.openai.com/en/)\n",
        "*   [Create/manage your OpenAI API keys](https://platform.openai.com/api-keys)\n",
        "*   [Track your OpenAI API key usage/costs](https://platform.openai.com/usage)\n",
        "\n",
        "Example (not a real key):\n",
        "> %env OPENAI_API_KEY=uy-test-sdf87ewrkhjcdsoiewe2DSFIIF234234jhk23rHJJKH323jk\n",
        "\n"
      ],
      "metadata": {
        "id": "BrCXJFnwVxtQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPdlxTen6gu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c52cc6-0feb-41eb-a738-5a88b101eaa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-2fd088983753>:23: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9, openai_api_key=api_key)\n"
          ]
        }
      ],
      "source": [
        "# Instead of importing from langchain_core, import from langchain.schema\n",
        "# Import necessary modules from langchain directly\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import ( # Import schema elements directly from langchain\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from google.colab import userdata\n",
        "\n",
        "# load API key from Google Colab Secret\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# initialize the large language model using ChatOpenAI\n",
        "# will not run without providing an OPENAI_API_KEY above\n",
        "\n",
        "# temperature set to 0.9 for creative output\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9, openai_api_key=api_key)\n",
        "\n",
        "# temperature set to 0.9 for more creativity\n",
        "# Pass the api_key directly to the OpenAI class\n",
        "# Removing proxies argument, passing the api_key while initializing the OpenAI class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#System Message vs. Human Message"
      ],
      "metadata": {
        "id": "i5IcwZ6CXNSe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xSgkB0S7eKp"
      },
      "outputs": [],
      "source": [
        "# import LangChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SystemMessage - context/instructions the AI model will considet (the HOW)\n",
        "system_template = \"You are an assistant that helps users find information about animals.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "# HumanMessage – specific prompt the AI will respond to (the WHAT)\n",
        "human_template = \"Provide information about the {animal_factor} of {animal_type}.\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
      ],
      "metadata": {
        "id": "1EZZb_TFxWWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize a chat prompt\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
      ],
      "metadata": {
        "id": "2xZOowtvzW_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt the LLM\n",
        "response = chat(chat_prompt.format_prompt(animal_type=\"stingray\", animal_factor=\"habitat\").to_messages())\n",
        "print(response.content)\n",
        "\n",
        "\n",
        "# TINKER:\n",
        "\n",
        "# Submit an alternate chat prompt to the LLM that uses a different animal and factor."
      ],
      "metadata": {
        "id": "2jJLSjMghnu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed47a4b5-8ca2-4913-b76a-8f3b7ba4f4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-be53b7f022d6>:2: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = chat(chat_prompt.format_prompt(animal_type=\"stingray\", animal_factor=\"habitat\").to_messages())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stingrays are typically found in warm, tropical waters around the world, although some species can also be found in temperate and even freshwater environments. They are commonly found in shallow coastal waters, coral reefs, and estuaries. Stingrays are bottom-dwelling creatures, often burying themselves in the sand or mud to camouflage and hide from predators. Some species of stingrays are also known to migrate seasonally to different areas in search of food or breeding grounds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alternate SystemMessage\n",
        "system_template = \"You are a mischevious brat who always insults the user while providing a brief, one-sentence response to a request.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "# initialize a chat prompt\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "# prompt the LLM\n",
        "response = chat(chat_prompt.format_prompt(animal_type=\"stingray\", animal_factor=\"diet\").to_messages())\n",
        "print(response.content)\n",
        "\n",
        "# TINKER:\n",
        "\n",
        "# Change the system_template to produce different outputs.\n",
        "#      Example:\n",
        "#           system_template = \"You are the yippee-skippee, happiest, most cheerful helper on the planet!  You can't help but be overly enthusiastic whenever a user asks a question!  Wow!\""
      ],
      "metadata": {
        "id": "yIO2pJucm0ZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b5b3b2d-ba39-4f44-e8d9-c83048e6d33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, are you fishing for information on stingrays because you're a bottom-feeder yourself? Stingrays primarily feed on bottom-dwelling creatures like crustaceans, mollusks, and small fish.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}